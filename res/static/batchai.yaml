excludes: ['.git','.svn']
cache_dir: ${BATCHAI_CACHE_DIR}
lang: ${LANG}
test:
  model_id: ${BATCHAI_TEST_MODEL}
  includes: ['*.py', '*.python', '*.cs', '*.cpp', '*.cc', '*.h', '*.hpp', '*.c', '*.ruby', '*.go', '*.java', '*.kt', '*.lua', '*.rs', '*.scala', '*.ts', '*.php', '*.swift', '*.pl']
  prompt:
    rules:
      - "${BATCHAI_TEST_RULE_1}"
      - "${BATCHAI_TEST_RULE_2}"
      - "${BATCHAI_TEST_RULE_3}"
      - "${BATCHAI_TEST_RULE_4}"
      - "${BATCHAI_TEST_RULE_5}"
      - "${BATCHAI_TEST_RULE_6}"
      - "${BATCHAI_TEST_RULE_7}"
      - "${BATCHAI_TEST_RULE_8}"
      - "${BATCHAI_TEST_RULE_9}"
      - "${BATCHAI_TEST_RULE_10}"
      - "${BATCHAI_TEST_RULE_11}"
      - "${BATCHAI_TEST_RULE_12}"
      - "${BATCHAI_TEST_RULE_13}"
      - "${BATCHAI_TEST_RULE_14}"
      - "${BATCHAI_TEST_RULE_15}"
      - "${BATCHAI_TEST_RULE_16}"
      - "${BATCHAI_TEST_RULE_17}"
      - "${BATCHAI_TEST_RULE_18}"
      - "${BATCHAI_TEST_RULE_19}"
      - "${BATCHAI_TEST_RULE_20}"
      - "${MY_TEST_RULE_1}"
      - "${MY_TEST_RULE_2}"
      - "${MY_TEST_RULE_3}"
      - "${MY_TEST_RULE_4}"
      - "${MY_TEST_RULE_5}"
      - "${MY_TEST_RULE_6}"
      - "${MY_TEST_RULE_7}"
      - "${MY_TEST_RULE_8}"
      - "${MY_TEST_RULE_9}"
      - "${MY_TEST_RULE_10}"
      - "${MY_TEST_RULE_11}"
      - "${MY_TEST_RULE_12}"
      - "${MY_TEST_RULE_13}"
      - "${MY_TEST_RULE_14}"
      - "${MY_TEST_RULE_15}"
      - "${MY_TEST_RULE_16}"
      - "${MY_TEST_RULE_17}"
      - "${MY_TEST_RULE_18}"
      - "${MY_TEST_RULE_19}"
      - "${MY_TEST_RULE_20}"
    template: |
        As an developer expert, you're requested to write test cases provided code following belows rules:

        {{.test_rules}}
        
        Path of code to test: {{.path}}
        
        Existing test code: 
        {{.existing_test_code}}
        
        Content of code to test:

        ```
        {{.code_to_test}}
        ```
check:
  model_id: ${BATCHAI_CHECK_MODEL}
  includes: ['Dockerfile','*.xml','*.py', '*.python', '*.cs', '*.cpp', '*.cc', '*.h', '*.hpp', '*.c', '*.ruby', '*.go', '*.html', '*.htm', '*.java', '*.json', '*.kt', '*.lua', '*.rs', '*.scala', '*.ts', '*.php', '*.proto', '*.swift', '*.md', '*.pl','*.sh','*.yaml','*.yml']
  severity: ${BATCHAI_CHECK_SEVERITY}
  prompt:
    rules:
      - "${BATCHAI_CHECK_RULE_1}"
      - "${BATCHAI_CHECK_RULE_2}"
      - "${BATCHAI_CHECK_RULE_3}"
      - "${BATCHAI_CHECK_RULE_4}"
      - "${BATCHAI_CHECK_RULE_5}"
      - "${BATCHAI_CHECK_RULE_6}"
      - "${BATCHAI_CHECK_RULE_7}"
      - "${BATCHAI_CHECK_RULE_8}"
      - "${BATCHAI_CHECK_RULE_9}"
      - "${BATCHAI_CHECK_RULE_10}"
      - "${BATCHAI_CHECK_RULE_11}"
      - "${BATCHAI_CHECK_RULE_12}"
      - "${BATCHAI_CHECK_RULE_13}"
      - "${BATCHAI_CHECK_RULE_14}"
      - "${BATCHAI_CHECK_RULE_15}"
      - "${BATCHAI_CHECK_RULE_16}"
      - "${BATCHAI_CHECK_RULE_17}"
      - "${BATCHAI_CHECK_RULE_18}"
      - "${BATCHAI_CHECK_RULE_19}"
      - "${BATCHAI_CHECK_RULE_20}"
      - "${MY_CHECK_RULE_1}"
      - "${MY_CHECK_RULE_2}"
      - "${MY_CHECK_RULE_3}"
      - "${MY_CHECK_RULE_4}"
      - "${MY_CHECK_RULE_5}"
      - "${MY_CHECK_RULE_6}"
      - "${MY_CHECK_RULE_7}"
      - "${MY_CHECK_RULE_8}"
      - "${MY_CHECK_RULE_9}"
      - "${MY_CHECK_RULE_10}"
      - "${MY_CHECK_RULE_11}"
      - "${MY_CHECK_RULE_12}"
      - "${MY_CHECK_RULE_13}"
      - "${MY_CHECK_RULE_14}"
      - "${MY_CHECK_RULE_15}"
      - "${MY_CHECK_RULE_16}"
      - "${MY_CHECK_RULE_17}"
      - "${MY_CHECK_RULE_18}"
      - "${MY_CHECK_RULE_19}"
      - "${MY_CHECK_RULE_20}"
    template: |
        As an developer expert, you're requested by users to check provided file:

        {{.check_rules}}
        
        Path of file to check: {{.path}}

        Content of file to check:
        
        ```
        {{.code_to_check}}
        ```

models:
  - id: openai/gpt-4o
    name: gpt-4o
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 128000
    max_completion_tokens: 256000
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ${OPENAI_PROXY_URL}
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ${OPENAI_PROXY_USER}
    proxy_pass: ${OPENAI_PROXY_PASS}

  - id: openai/gpt-4o-mini
    name: gpt-4o-mini
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 128000
    max_completion_tokens: 256000
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ${OPENAI_PROXY_URL}
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ${OPENAI_PROXY_USER}
    proxy_pass: ${OPENAI_PROXY_PASS}

  - id: openai/gpt-4-turbo
    name: gpt-4-turbo
    context_window: 12800
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    max_completion_tokens: 32768
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ${OPENAI_PROXY_URL}
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ${OPENAI_PROXY_USER}
    proxy_pass: ${OPENAI_PROXY_PASS}

  - id: openai/gpt-4
    name: gpt-4
    context_window: 8192
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    max_completion_tokens: 32768
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ${OPENAI_PROXY_URL}
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ${OPENAI_PROXY_USER}
    proxy_pass: ${OPENAI_PROXY_PASS}

  - id: openai/gpt-3.5-turbo
    name: gpt-3.5-turbo
    context_window: 16385
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    max_completion_tokens: 32768
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ${OPENAI_PROXY_URL}
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ${OPENAI_PROXY_USER}
    proxy_pass: ${OPENAI_PROXY_PASS}

  - id: openai/gpt-3.5-turbo-instruct
    name: gpt-3.5-turbo-instruct
    context_window: 4096
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    max_completion_tokens: 8192
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ${OPENAI_PROXY_URL}
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ${OPENAI_PROXY_USER}
    proxy_pass: ${OPENAI_PROXY_PASS}

  - id: tongyi/qwen2.5-coder-7b-instruct
    name: qwen2.5-coder-7b-instruct
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 32768
    max_completion_tokens: 65536
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${QWEN_API_KEY}
    base_url: ${QWEN_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''

  - id: ollama/qwen2.5-coder:7b-instruct-fp16
    name: qwen2.5-coder:7b-instruct-fp16
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 131072
    max_completion_tokens: 262144
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OLLAMA_API_KEY}
    base_url: ${OLLAMA_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''

  - id: ollama/qwen2.5-coder:7b-instruct-q4_0
    name: qwen2.5-coder:7b-instruct-q4_0
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 131072
    max_completion_tokens: 262144
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OLLAMA_API_KEY}
    base_url: ${OLLAMA_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''

  - id: ollama/qwen2.5-coder:7b-instruct-q8_0
    name: qwen2.5-coder:7b-instruct-q8_0
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 131072
    max_completion_tokens: 262144
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OLLAMA_API_KEY}
    base_url: ${OLLAMA_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''

  - id: ollama/qwen2.5-coder:14b-instruct-fp16
    name: qwen2.5-coder:14b-instruct-fp16
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 131072
    max_completion_tokens: 262144
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OLLAMA_API_KEY}
    base_url: ${OLLAMA_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''

  - id: ollama/qwen2.5-coder:14b-instruct-q4_1
    name: qwen2.5-coder:14b-instruct-q4_1
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 131072
    max_completion_tokens: 262144
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OLLAMA_API_KEY}
    base_url: ${OLLAMA_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''

  - id: ollama/qwen2.5-coder:14b-instruct-q8_0
    name: qwen2.5-coder:14b-instruct-q8_0
    temperature: ${BATCHAI_CHAT_TEMERATURE}
    context_window: 131072
    max_completion_tokens: 262144
    tik_token_enabled: ${BATCHAI_ENABLE_TIK_TOKEN}
    api_key: ${OLLAMA_API_KEY}
    base_url: ${OLLAMA_BASE_URL}
    timeout: ${BATCHAI_API_TIMEOUT}
    proxy_url: ''
    proxy_insecure_skip_verify: ${BATCHAI_PROXY_INSECURE_SKIP_VERIFY}
    proxy_user: ''
    proxy_pass: ''